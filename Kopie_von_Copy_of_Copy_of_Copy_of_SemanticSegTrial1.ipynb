{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NouranShaaban/workshop_geopython2019/blob/master/Kopie_von_Copy_of_Copy_of_Copy_of_SemanticSegTrial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-m9Jl447zhDy",
        "outputId": "99c85d8f-e39a-4766-f67e-77a7dacec013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.8/dist-packages (0.19.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (23.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xjxQkPu217nV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "import glob\n",
        "import numpy as np\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NNqsLyCc17qA"
      },
      "outputs": [],
      "source": [
        "# Set the directory where the images are stored\n",
        "image_dir = '/content/IMAGES'\n",
        "\n",
        "# Create an empty list to store the image data\n",
        "image_data = []\n",
        "\n",
        "# Use glob to get a list of all the image filenames\n",
        "filenames = glob.glob(image_dir + '/*.jpg')\n",
        "\n",
        "# Loop through the filenames and load the images\n",
        "for filename in filenames:\n",
        "    # Load the image and convert it to grayscale\n",
        "    image = Image.open(filename).convert('L')\n",
        "  \n",
        "    # Resize the image to a consistent size\n",
        "    image = image.resize((256, 256))\n",
        "    # Convert the image to a numpy array\n",
        "    image_array = np.array(image)\n",
        "    \n",
        "    # Append the image array to the list\n",
        "    image_data.append(image_array)\n",
        "\n",
        "# Convert the list of image arrays to a NumPy array\n",
        "image_data = np.array(image_data)\n",
        "\n",
        "# Save the image data to a file\n",
        "np.save('image_data.npy', image_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lc3OdKlt17si"
      },
      "outputs": [],
      "source": [
        "image_data = image_data.reshape((-1,256,256,1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_89rfZw017vF"
      },
      "outputs": [],
      "source": [
        "# Set the directory where the images are stored\n",
        "label_dir = '/content/MASKS'\n",
        "\n",
        "# Create an empty list to store the image data\n",
        "label_data = []\n",
        "# Number of classes\n",
        "num_classes = 4\n",
        "\n",
        "# Use glob to get a list of all the image filenames\n",
        "filenames = glob.glob(label_dir + '/*.png')\n",
        "\n",
        "# Loop through the filenames and load the images\n",
        "for filename in filenames:\n",
        "    # Load the image and convert it to grayscale\n",
        "    label = Image.open(filename)#.convert('L')\n",
        "    \n",
        "    # Resize the image to a consistent size\n",
        "    label = label.resize((256, 256))\n",
        "    # Convert the image to a numpy array\n",
        "    label_array = np.array(label)\n",
        " \n",
        "    \n",
        "    # Append the image array to the list\n",
        "    label_data.append(label_array)\n",
        "\n",
        "label_data = np.array(label_data)\n",
        "\n",
        "# Save the image data to a file\n",
        "np.save('label_data.npy', label_data)\n",
        "\n",
        "##########################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qBe4QTw517xR",
        "outputId": "cb6b4e34-6317-462c-c3a1-87b00d22f60c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1048576"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "label_data.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kF1d0Ty417z7"
      },
      "outputs": [],
      "source": [
        "\n",
        "one_hot_labels = np.zeros((len(label_data), 256, 256, num_classes))\n",
        "\n",
        "# Iterate over the label images\n",
        "for i, label_image in enumerate(label_data):\n",
        "    # one-hot encode the labels\n",
        "    one_hot_labels[i] = np.eye(num_classes)[label_image]\n",
        "\n",
        "    class_names = ['Background','panel','panelWfrost','Thicknow']\n",
        "\n",
        "# Get the index of the class with the highest probability\n",
        "label_index = np.argmax(one_hot_labels, axis=-1)\n",
        "\n",
        "# Get the name of the class\n",
        "label_index = label_index.astype(int)\n",
        "class_name = np.vectorize(lambda x: class_names[x])(label_index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1Gre9jE5172Z",
        "outputId": "76eae101-9e96-4b97-d8de-d28b9f440e0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 256, 256, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "one_hot_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0gwBvqRm1741",
        "outputId": "a0dd7feb-f998-4704-9269-34d5f45d37ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "one_hot_labels[0,:,:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "jV9GPeS-177Q",
        "outputId": "c269e80c-fc76-4e14-8a0b-5e208c89e3fa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Load the image data\n",
        "label_data = np.load('label_data.npy')\n",
        "\n",
        "# Number of classes\n",
        "num_classes = 4\n",
        "\n",
        "# Create an empty array to store the one-hot encoded labels\n",
        "one_hot_labels = np.zeros((len(label_data), 256, 256, num_classes))\n",
        "\n",
        "# Iterate over the label images\n",
        "for i, label_image in enumerate(label_data):\n",
        "    # One-hot encode the labels\n",
        "    for j in range(num_classes):\n",
        "        one_hot_labels[i,:,:,j] = (label_image == j)\n",
        "\n",
        "# Get the index of the class with the highest probability\n",
        "label_index = np.argmax(one_hot_labels, axis=-1)\n",
        "\n",
        "# Get the name of the class\n",
        "class_names = ['Background','panel','panelWfrost','Thicksnow']\n",
        "\n",
        "# display the one-hot encoded image\n",
        "img = label_index[1]\n",
        "plt.imshow(img)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "ncmCTCos179w",
        "outputId": "6f485078-cd54-494e-c35a-04471ab7d66a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "class_3 = np.where(label_index[4] == 0, 1,0)\n",
        "class_3 = class_3.reshape((256,256))\n",
        "plt.imshow(class_3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(label_index[4] == 1, 0,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "swbYfNdwKo0x",
        "outputId": "b20b5586-4e6d-400a-bb6e-7c2799840e4e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " ...\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]] 0 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BTux8cGt18AW"
      },
      "outputs": [],
      "source": [
        "class_counts = []\n",
        "for i in range(num_classes):\n",
        "    class_mask = np.where(label_index[4] == i, 1, 0)\n",
        "    class_counts.append(np.sum(class_mask))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3aDZgKoS18DB",
        "outputId": "7b1f8891-dadd-4f50-ba83-35725fb56ccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[39775, 25761, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "print(class_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9i3IAF7Y2YSA"
      },
      "outputs": [],
      "source": [
        "def upsample_block(x, conv_features, n_filters):\n",
        "   # upsample\n",
        "   x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
        "   # concatenate\n",
        "   x = layers.concatenate([x, conv_features])\n",
        "   # dropout\n",
        "   x = layers.Dropout(0.3)(x)\n",
        "   # Conv2D twice with ReLU activation\n",
        "   x = double_conv_block(x, n_filters)\n",
        "   # add another Conv2D layer\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "\n",
        "   return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CVMQYuy72YU2"
      },
      "outputs": [],
      "source": [
        "def downsample_block(x, n_filters):\n",
        "   f = double_conv_block(x, n_filters)\n",
        "   p = layers.MaxPool2D(2)(f)\n",
        "   p = layers.Dropout(0.3)(p)\n",
        "\n",
        "   return f, p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "icMPQTy82YXs"
      },
      "outputs": [],
      "source": [
        "def double_conv_block(x, n_filters):\n",
        "   # Conv2D then ReLU activation\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "   # Conv2D then ReLU activation\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "   # add another Conv2D layer\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "   # add another Conv2D layer\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "\n",
        "   return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "M4rjSNjE4L9i"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2OYaRXbZ5wWW"
      },
      "outputs": [],
      "source": [
        " # inputs\n",
        "import tensorflow.keras.layers as layers\n",
        " \n",
        "inputs = layers.Input(shape=(256,256,1))\n",
        "\n",
        "# encoder: contracting path - downsample\n",
        "# 1 - downsample\n",
        "f1, p1 = downsample_block(inputs, 64)\n",
        "# 2 - downsample\n",
        "f2, p2 = downsample_block(p1, 128)\n",
        "# 3 - downsample\n",
        "f3, p3 = downsample_block(p2, 256)\n",
        "# 4 - downsample\n",
        "f4, p4 = downsample_block(p3, 512)\n",
        "\n",
        "# 5 - bottleneck\n",
        "bottleneck = double_conv_block(p4, 1024)\n",
        "\n",
        "# decoder: expanding path - upsample\n",
        "# 6 - upsample\n",
        "u6 = upsample_block(bottleneck, f4, 512)\n",
        "# 7 - upsample\n",
        "u7 = upsample_block(u6, f3, 256)\n",
        "# 8 - upsample\n",
        "u8 = upsample_block(u7, f2, 128)\n",
        "# 9 - upsample\n",
        "u9 = upsample_block(u8, f1, 64)\n",
        "\n",
        "# outputs\n",
        "outputs = layers.Conv2D(num_classes, 1, padding=\"same\", activation = \"softmax\")(u9)\n",
        "\n",
        "# unet model with Keras Functional API\n",
        "unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RJeesHOhHqCL",
        "outputId": "20f2f99c-ef51-43a3-8d4f-68a51f34f5d8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"U-Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 256, 256, 64  640         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['conv2d[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 256, 256, 64  36928       ['conv2d_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 256, 256, 64  36928       ['conv2d_2[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['conv2d_3[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 128, 128, 64  0           ['max_pooling2d[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 128, 128, 12  73856       ['dropout[0][0]']                \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_4[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_5[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_6[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 64, 64, 128)  0           ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 64, 64, 256)  295168      ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 64, 64, 256)  590080      ['conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['conv2d_11[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 32, 32, 256)  0           ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 32, 32, 512)  1180160     ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0          ['conv2d_15[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 16, 16, 512)  0           ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 16, 16, 1024  4719616     ['dropout_3[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 16, 16, 1024  9438208     ['conv2d_16[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 16, 16, 1024  9438208     ['conv2d_17[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 16, 16, 1024  9438208     ['conv2d_18[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 32, 32, 512)  4719104    ['conv2d_19[0][0]']              \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 32, 32, 1024  0           ['conv2d_transpose[0][0]',       \n",
            "                                )                                 'conv2d_15[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 32, 32, 1024  0           ['concatenate[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 32, 32, 512)  4719104     ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_20[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_23[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 256)  1179904    ['conv2d_24[0][0]']              \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 64, 64, 512)  0           ['conv2d_transpose_1[0][0]',     \n",
            "                                                                  'conv2d_11[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 64, 64, 512)  0           ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 64, 64, 256)  1179904     ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_27[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_28[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 12  295040     ['conv2d_29[0][0]']              \n",
            " spose)                         8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 128, 128, 25  0           ['conv2d_transpose_2[0][0]',     \n",
            "                                6)                                'conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 128, 128, 25  0           ['concatenate_2[0][0]']          \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 128, 128, 12  295040      ['dropout_6[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_30[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_31[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_32[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_33[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 64  73792      ['conv2d_34[0][0]']              \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 256, 256, 12  0           ['conv2d_transpose_3[0][0]',     \n",
            "                                8)                                'conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 256, 256, 12  0           ['concatenate_3[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 256, 256, 64  73792       ['dropout_7[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_35[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_36[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_37[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_38[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 256, 256, 4)  260         ['conv2d_39[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 69,060,804\n",
            "Trainable params: 69,060,804\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "fME0ebJ72YaT"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "\n",
        "# x = unet_model.outputs\n",
        "\n",
        "# # Compile the model\n",
        "# unet_model = keras.Model(inputs, x)\n",
        "unet_model.compile(optimizer='ADAM', loss=tf.losses.CategoricalCrossentropy(), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Yf2v-J7p2Yc6",
        "outputId": "f312e59d-392d-4771-aea3-6e5cf848f194"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 256, 256, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "image_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KRpK9z2UFmjc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "S1zutHpFYuTh"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(image_data, one_hot_labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "livp2L57b2FC",
        "outputId": "16a6ced4-36f3-404d-947f-77a112df6617"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 256, 256, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "train_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IyK3g-33Cn5f",
        "outputId": "7df7a15a-bd52-4add-a104-c49b89b2a125"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 256, 256, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "H9-wCkBOvLst",
        "outputId": "261ebc55-389c-42a6-b1d1-23cd652bbbd5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 256, 256, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "test_labels.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KzpiviOJFo8g"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "oPuMkIdKCnCa",
        "outputId": "07cf54d7-b705-43fe-fa16-ef1aeb8835fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 256, 256, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "test_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "n6METtkbZ90l",
        "outputId": "cd129128-b7cd-49d2-fba0-832c8ea8a20e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 236s 20s/step - loss: 8.7684 - accuracy: 0.5949 - val_loss: 1.7111 - val_accuracy: 0.5881\n",
            "Epoch 2/10\n",
            "10/12 [========================>.....] - ETA: 33s - loss: 1.3100 - accuracy: 0.5957"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-7366f6f0b21e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history = unet_model.fit(datagen.flow(train_images, train_labels, batch_size=1), epochs=10, validation_data=(test_images, test_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unet_model.save('unet_model.h5')"
      ],
      "metadata": {
        "id": "fmcRU32GDNeU"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GtfOB0FdIblz",
        "outputId": "0cd58b47-4beb-42eb-a930-0b426301b3ac"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 256, 256, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G_ZgmI7CKDPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_model.summary()"
      ],
      "metadata": {
        "id": "GZbySH7zKDia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tcwUgCEHIcn1",
        "outputId": "bfae4fd1-e362-4eeb-e06f-23c5744d120d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.argmax(predictions[0], axis=-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QVr47jj7I66h",
        "outputId": "3e9de571-9556-4d81-9d4c-2a2d1280ddaa"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]\n",
            " ...\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 # Load the test image in color format\n",
        "test_image = cv2.imread('test_image.jpg')\n",
        "\n",
        "# Resize the test image to the desired size\n",
        "test_image = cv2.resize(test_image, (256, 256))\n",
        "\n",
        "# Convert the test image to grayscale\n",
        "gray_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Preprocess the test image\n",
        "gray_image = gray_image.astype('float32') / 255.0\n",
        "\n",
        "# Reshape the grayscale image to match the model input shape\n",
        "gray_image = gray_image.reshape((1, 256, 256, 1))\n",
        "\n",
        "# Make predictions on the test image\n",
        "predictions = unet_model.predict(gray_image)\n",
        "\n",
        "# Get the predicted class labels for the test image\n",
        "predicted_labels = np.eye(4)[np.argmax(predictions[0], axis=-1)]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "I-PlpVH5COj-",
        "outputId": "f0a2e3f8-b077-459b-a8a2-b0e7a210e3da"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 5s 5s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predicted_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4Kh2tnF7CjAL",
        "outputId": "5e2f084c-5050-453e-fcb3-eef246abc3eb"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  ...\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  ...\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  ...\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  ...\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  ...\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  ...\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predicted_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0o497LE3My8J",
        "outputId": "666f6c5e-f5aa-4e69-83a0-84587800c7f7"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 256, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predicted_one_hot_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YlLO7hGiNnay",
        "outputId": "e6afdcfc-5ff6-4b4e-9d97-7d97458976f0"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 256, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted class labels for the test image\n",
        "predicted_labels = np.eye(4)[np.argmax(predictions[0], axis=-1)]"
      ],
      "metadata": {
        "id": "dHMzRvtEef1M"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have `predicted_labels` as an array of shape (1, 256, 256, 4) containing the predicted labels\n",
        "num_classes = 4\n",
        "\n",
        "predicted_one_hot_labels = np.zeros((predicted_labels.shape[0], predicted_labels.shape[1], num_classes), dtype=np.float32)\n",
        "\n",
        "# One-hot encode the predicted labels\n",
        "for j in range(num_classes):\n",
        "    predicted_one_hot_labels[:,:,j] = (predicted_labels[:,:,0] == j)\n",
        "\n",
        "\n",
        "# Get the index of the class with the highest probability\n",
        "predicted_label_index = np.eye(4)[np.argmax(predicted_one_hot_labels, axis=-1)]\n",
        "\n",
        "# Get the name of the class\n",
        "class_names = ['Background','panel','panelWfrost','Thicksnow']\n",
        "\n",
        "# Display the one-hot encoded image\n",
        "img = predicted_label_index[0]\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "# Count the number of pixels in each class\n",
        "class_counts = []\n",
        "for i in range(num_classes):\n",
        "    class_mask = np.where(predicted_label_index[0] == i, 1, 0)\n",
        "    class_counts.append(np.sum(class_mask))\n",
        "\n",
        "# Display the class counts\n",
        "for i in range(num_classes):\n",
        "    print(f\"Number of pixels in class '{class_names[i]}': {class_counts[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "2CXLH5W8Qwbu",
        "outputId": "0a0f783b-25d7-4669-99c5-7a257b80bae3"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of pixels in class 'Background': 768\n",
            "Number of pixels in class 'panel': 256\n",
            "Number of pixels in class 'panelWfrost': 0\n",
            "Number of pixels in class 'Thicksnow': 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BEY2ds3Deedr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_one_hot_labels = np.zeros((1, 256, 256, num_classes))\n",
        "# One-hot encode the predicted labels\n",
        "for j in range(num_classes):\n",
        "    predicted_one_hot_labels[:,:,j] = (predicted_labels == j)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "g5-Zae6XO1dg",
        "outputId": "6901a75f-937a-4e1d-9a00-99cb759bc42e"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-f9f4f0ae6d9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# One-hot encode the predicted labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpredicted_one_hot_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted_labels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (256,256) into shape (1,256,4)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have `predicted_labels` as an array of shape (1, 256, 256, 4) containing the predicted labels\n",
        "num_classes = 4\n",
        "\n",
        "# Create an empty array to store the one-hot encoded labels\n",
        "predicted_one_hot_labels = np.zeros((1, 256, 256, num_classes))\n",
        "\n",
        "# Iterate over the predicted label images\n",
        "for i in range(predicted_labels.shape[0]):\n",
        "    # One-hot encode the predicted labels\n",
        "    for j in range(num_classes):\n",
        "        predicted_one_hot_labels[i,:,:,j] = (predicted_labels[:,:,:] == j)\n",
        "\n",
        "# Get the index of the class with the highest probability\n",
        "predicted_label_index = np.argmax(predicted_one_hot_labels, axis=-1)\n",
        "\n",
        "# Get the name of the class\n",
        "class_names = ['Background','panel','panelWfrost','Thicksnow']\n",
        "\n",
        "# Display the one-hot encoded image\n",
        "img = predicted_label_index[0]\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "# Count the number of pixels in each class\n",
        "class_counts = []\n",
        "for i in range(num_classes):\n",
        "    class_mask = np.where(predicted_label_index[0] == i, 1, 0)\n",
        "    class_counts.append(np.sum(class_mask))\n",
        "\n",
        "# Display the class counts\n",
        "for i in range(num_classes):\n",
        "    print(f\"Number of pixels in class '{class_names[i]}': {class_counts[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "7aeJPbA5CO0j",
        "outputId": "0dbee4d2-32b1-4e5c-cd5a-d3b0b192b2c8"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-4ee601f961f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# One-hot encode the predicted labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpredicted_one_hot_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Get the index of the class with the highest probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (256,256,4) into shape (256,256)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predicted_one_hot_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "puvtMQR6CO6m",
        "outputId": "d6f3d687-4b7e-48c3-d035-7cfcd0ed88b3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 256, 256, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4-PPKs5-CPD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DzInzd-HCPHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "\n",
        "# Define the color coding for each class\n",
        "class_colors = [(0, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
        "\n",
        "# Load the test image and ground truth mask in color format\n",
        "test_image = cv2.imread('test_image.jpg')\n",
        "ground_truth_mask = cv2.imread('ground_truth_mask.png')\n",
        "\n",
        "# Resize the test image and ground truth mask to the desired size\n",
        "test_image = cv2.resize(test_image, (256, 256))\n",
        "ground_truth_mask = cv2.resize(ground_truth_mask, (256, 256))\n",
        "\n",
        "# Convert the test image and ground truth mask to grayscale\n",
        "gray_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
        "gray_ground_truth_mask = cv2.cvtColor(ground_truth_mask, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Preprocess the test image\n",
        "gray_image = gray_image.astype('float32') / 255.0\n",
        "\n",
        "# Reshape the grayscale image to match the model input shape\n",
        "gray_image = gray_image.reshape((1, 256, 256, 1))\n",
        "\n",
        "# Make predictions on the test image\n",
        "predictions = unet_model.predict(gray_image)\n",
        "\n",
        "# Get the predicted class labels for the test image\n",
        "predicted_labels = np.argmax(predictions[0], axis=-1)\n",
        "\n",
        "# Apply color coding to the predicted image and the ground truth image\n",
        "predicted_mask = np.zeros_like(test_image)\n",
        "ground_truth_colored = np.zeros_like(ground_truth_mask)\n",
        "for i, color in enumerate(class_colors):\n",
        "    predicted_mask[predicted_labels == i] = color\n",
        "    ground_truth_colored[gray_ground_truth_mask == i * 255] = color\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Display the predicted image and the ground truth image\n",
        "cv2_imshow( predicted_mask)\n",
        "cv2_imshow( ground_truth_colored)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "FGdSM59lg5u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "\n",
        "# Define the color coding for each class\n",
        "class_colors = [(0, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
        "\n",
        "# Load the test image and ground truth mask in color format\n",
        "test_image = cv2.imread('test_image.jpg')\n",
        "ground_truth_mask = cv2.imread('ground_truth_mask.png')\n",
        "\n",
        "# Convert the test image and ground truth mask to grayscale\n",
        "gray_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
        "gray_ground_truth_mask = cv2.cvtColor(ground_truth_mask, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Resize the test image to 256x256\n",
        "gray_image = cv2.resize(gray_image, (256, 256), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "# Preprocess the test image\n",
        "gray_image = gray_image.astype('float32') / 255.0\n",
        "\n",
        "# Reshape the grayscale image to match the model input shape\n",
        "gray_image = gray_image.reshape((1, 256, 256, 1))\n",
        "\n",
        "# Make predictions on the test image\n",
        "predictions = unet_model.predict(gray_image)\n",
        "\n",
        "# Get the predicted class labels for the test image\n",
        "predicted_labels = np.argmax(predictions[0], axis=-1)\n",
        "\n",
        "# Apply color coding to the predicted image and the ground truth image\n",
        "predicted_mask = np.zeros_like(test_image)\n",
        "ground_truth_colored = np.zeros_like(ground_truth_mask)\n",
        "for i, color in enumerate(class_colors):\n",
        "    predicted_mask[predicted_labels == i] = color\n",
        "    ground_truth_colored[gray_ground_truth_mask == i * 255] = color\n",
        "\n",
        "# Display the predicted image and the ground truth image\n",
        "cv2.imshow('Predicted Mask', predicted_mask)\n",
        "cv2.imshow('Ground Truth Mask', ground_truth_colored)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "kvtVUpGSglZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "\n",
        "# Define the color coding for each class\n",
        "class_colors = [(0, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
        "\n",
        "# Load the test image and ground truth mask in color format\n",
        "test_image = cv2.imread('test_image.jpg')\n",
        "ground_truth_mask = cv2.imread('ground_truth_mask.png')\n",
        "\n",
        "# Convert the test image and ground truth mask to grayscale\n",
        "gray_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
        "gray_ground_truth_mask = cv2.cvtColor(ground_truth_mask, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Preprocess the test image\n",
        "gray_image = cv2.resize(gray_image, (256, 256))\n",
        "gray_image = gray_image.astype('float32') / 255.0\n",
        "\n",
        "# Reshape the grayscale image to match the model input shape\n",
        "gray_image = gray_image.reshape((1, 256, 256, 1))\n",
        "\n",
        "# Make predictions on the test image\n",
        "predictions = unet_model.predict(gray_image)\n",
        "\n",
        "# Get the predicted class labels for the test image\n",
        "predicted_labels = np.argmax(predictions[0], axis=-1)\n",
        "\n",
        "# Apply color coding to the predicted image and the ground truth image\n",
        "predicted_mask = np.zeros_like(test_image)\n",
        "ground_truth_colored = np.zeros_like(ground_truth_mask)\n",
        "for i, color in enumerate(class_colors):\n",
        "    predicted_mask[predicted_labels == i] = color\n",
        "    ground_truth_colored[gray_ground_truth_mask == i * 255] = color\n",
        "\n",
        "# Display the predicted image and the ground truth image\n",
        "cv2.imshow('Predicted Mask', predicted_mask)\n",
        "cv2.imshow('Ground Truth Mask)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "SZNdBGO0fzSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YGt_BOIjfznU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 \n",
        "# Load the test image in color format\n",
        "test_image = cv2.imread('test_image.jpg')\n",
        "\n",
        "# Convert the test image to grayscale\n",
        "gray_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Preprocess the test image\n",
        "gray_image = cv2.resize(gray_image, (256, 256))\n",
        "gray_image = gray_image.astype('float32') / 255.0\n",
        "\n",
        "# Reshape the grayscale image to match the model input shape\n",
        "gray_image = gray_image.reshape((1, 256, 256, 1))\n",
        "\n",
        "# Make predictions on the test image\n",
        "predictions = unet_model.predict(gray_image)\n",
        "\n",
        "# Get the predicted class labels for the test image\n",
        "predicted_labels = np.argmax(predictions[0], axis=-1)\n",
        "\n",
        "# Calculate the pixel counts for each class in the predicted labels\n",
        "class_counts = []\n",
        "for i in range(num_classes):\n",
        "    class_mask = np.where(predicted_labels == i, 1, 0)\n",
        "    class_counts.append(np.sum(class_mask))\n",
        "    \n",
        "# Print the pixel counts for each class\n",
        "print('Pixel counts for each class:', class_counts)\n",
        "print()"
      ],
      "metadata": {
        "id": "3xk6Ieg_dmcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(class)"
      ],
      "metadata": {
        "id": "BVDwBQJW_RaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the test image in color format\n",
        "test_image = cv2.imread('test_image.jpg')\n",
        "\n",
        "# Convert the test image to grayscale\n",
        "gray_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Preprocess the test image\n",
        "gray_image = cv2.resize(gray_image, (256, 256))\n",
        "gray_image = gray_image.astype('float32') / 255.0\n",
        "\n",
        "# Reshape the grayscale image to match the model input shape\n",
        "gray_image = gray_image.reshape((1, 256, 256, 1))\n",
        "\n",
        "# Make predictions on the test image\n",
        "predictions = unet_model.predict(gray_image)\n",
        "\n",
        "# Get the predicted class labels for the test image\n",
        "predicted_labels = np.argmax(predictions[0], axis=-1)\n",
        "\n",
        "# Plot the test image and predicted segmentation mask\n",
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n",
        "ax1.imshow(test_image)\n",
        "ax1.set_title('Test Image')\n",
        "ax2.imshow(predicted_labels, cmap='gray')\n",
        "ax2.set_title('Segmentation Mask')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PJ6SyTVbdnQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7PGJhimxYZDA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPymgdnyR1j4zeEbObaRJQK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}