{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NouranShaaban/workshop_geopython2019/blob/master/Kopie_von_Copy_of_Copy_of_Copy_of_SemanticSegTrial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-m9Jl447zhDy",
        "outputId": "a5423b5f-0da0-4189-f5f7-fd9652cc4c6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.8/dist-packages (0.19.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (23.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (2.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xjxQkPu217nV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "import glob\n",
        "import numpy as np\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NNqsLyCc17qA"
      },
      "outputs": [],
      "source": [
        "# Set the directory where the images are stored\n",
        "image_dir = '/content/IMAGES'\n",
        "\n",
        "# Create an empty list to store the image data\n",
        "image_data = []\n",
        "\n",
        "# Use glob to get a list of all the image filenames\n",
        "filenames = glob.glob(image_dir + '/*.jpg')\n",
        "\n",
        "# Loop through the filenames and load the images\n",
        "for filename in filenames:\n",
        "    # Load the image and convert it to grayscale\n",
        "    image = Image.open(filename).convert('L')\n",
        "  \n",
        "    # Resize the image to a consistent size\n",
        "    image = image.resize((256, 256))\n",
        "    # Convert the image to a numpy array\n",
        "    image_array = np.array(image)\n",
        "    \n",
        "    # Append the image array to the list\n",
        "    image_data.append(image_array)\n",
        "\n",
        "# Convert the list of image arrays to a NumPy array\n",
        "image_data = np.array(image_data)\n",
        "\n",
        "# Save the image data to a file\n",
        "np.save('image_data.npy', image_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lc3OdKlt17si"
      },
      "outputs": [],
      "source": [
        "image_data = image_data.reshape((-1,256,256,1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_89rfZw017vF"
      },
      "outputs": [],
      "source": [
        "# Set the directory where the images are stored\n",
        "label_dir = '/content/MASKS'\n",
        "\n",
        "# Create an empty list to store the image data\n",
        "label_data = []\n",
        "# Number of classes\n",
        "num_classes = 4\n",
        "\n",
        "# Use glob to get a list of all the image filenames\n",
        "filenames = glob.glob(label_dir + '/*.png')\n",
        "\n",
        "# Loop through the filenames and load the images\n",
        "for filename in filenames:\n",
        "    # Load the image and convert it to grayscale\n",
        "    label = Image.open(filename)#.convert('L')\n",
        "    \n",
        "    # Resize the image to a consistent size\n",
        "    label = label.resize((256, 256))\n",
        "    # Convert the image to a numpy array\n",
        "    label_array = np.array(label)\n",
        " \n",
        "    \n",
        "    # Append the image array to the list\n",
        "    label_data.append(label_array)\n",
        "\n",
        "label_data = np.array(label_data)\n",
        "\n",
        "# Save the image data to a file\n",
        "np.save('label_data.npy', label_data)\n",
        "\n",
        "##########################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qBe4QTw517xR",
        "outputId": "5c84f6cb-ba0a-471c-b607-e61bcec72ac5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1114112"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "label_data.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kF1d0Ty417z7"
      },
      "outputs": [],
      "source": [
        "\n",
        "one_hot_labels = np.zeros((len(label_data), 256, 256, num_classes))\n",
        "\n",
        "# Iterate over the label images\n",
        "for i, label_image in enumerate(label_data):\n",
        "    # one-hot encode the labels\n",
        "    one_hot_labels[i] = np.eye(num_classes)[label_image]\n",
        "\n",
        "    class_names = ['Background','panel','panelWfrost','Thicknow']\n",
        "\n",
        "# Get the index of the class with the highest probability\n",
        "label_index = np.argmax(one_hot_labels, axis=-1)\n",
        "\n",
        "# Get the name of the class\n",
        "label_index = label_index.astype(int)\n",
        "class_name = np.vectorize(lambda x: class_names[x])(label_index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1Gre9jE5172Z",
        "outputId": "6f114e92-b875-4544-e3d9-a90a3c3a693a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17, 256, 256, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "one_hot_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0gwBvqRm1741",
        "outputId": "81a31230-0a3c-4758-8c8d-1d35e831cb95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "one_hot_labels[0,:,:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "jV9GPeS-177Q",
        "outputId": "f5329c8c-5bd2-4af6-d293-3ae62c1921f1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Load the image data\n",
        "label_data = np.load('label_data.npy')\n",
        "\n",
        "# Number of classes\n",
        "num_classes = 4\n",
        "\n",
        "# Create an empty array to store the one-hot encoded labels\n",
        "one_hot_labels = np.zeros((len(label_data), 256, 256, num_classes))\n",
        "\n",
        "# Iterate over the label images\n",
        "for i, label_image in enumerate(label_data):\n",
        "    # One-hot encode the labels\n",
        "    for j in range(num_classes):\n",
        "        one_hot_labels[i,:,:,j] = (label_image == j)\n",
        "\n",
        "# Get the index of the class with the highest probability\n",
        "label_index = np.argmax(one_hot_labels, axis=-1)\n",
        "\n",
        "# Get the name of the class\n",
        "class_names = ['Background','panel','panelWfrost','Thicksnow']\n",
        "\n",
        "# display the one-hot encoded image\n",
        "img = label_index[1]\n",
        "plt.imshow(img)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "ncmCTCos179w",
        "outputId": "3dc9d0f3-c0b6-4033-cb59-88decd4672d8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "class_3 = np.where(label_index[4] == 0, 1,0)\n",
        "class_3 = class_3.reshape((256,256))\n",
        "plt.imshow(class_3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "swbYfNdwKo0x"
      },
      "outputs": [],
      "source": [
        "#print(label_index[4] == 1, 0,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BTux8cGt18AW"
      },
      "outputs": [],
      "source": [
        "class_counts = []\n",
        "for i in range(num_classes):\n",
        "    class_mask = np.where(label_index[4] == i, 1, 0)\n",
        "    class_counts.append(np.sum(class_mask))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3aDZgKoS18DB",
        "outputId": "35f1c08f-a9b6-48ca-8e55-9c708ccd0d0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[40478, 8497, 0, 16561]\n"
          ]
        }
      ],
      "source": [
        "print(class_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9i3IAF7Y2YSA"
      },
      "outputs": [],
      "source": [
        "def upsample_block(x, conv_features, n_filters):\n",
        "   # upsample\n",
        "   x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
        "   # concatenate\n",
        "   x = layers.concatenate([x, conv_features])\n",
        "   # dropout\n",
        "   x = layers.Dropout(0.3)(x)\n",
        "   # Conv2D twice with ReLU activation\n",
        "   x = double_conv_block(x, n_filters)\n",
        "   # add another Conv2D layer\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "\n",
        "   return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CVMQYuy72YU2"
      },
      "outputs": [],
      "source": [
        "def downsample_block(x, n_filters):\n",
        "   f = double_conv_block(x, n_filters)\n",
        "   p = layers.MaxPool2D(2)(f)\n",
        "   p = layers.Dropout(0.3)(p)\n",
        "\n",
        "   return f, p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "icMPQTy82YXs"
      },
      "outputs": [],
      "source": [
        "def double_conv_block(x, n_filters):\n",
        "   # Conv2D then ReLU activation\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "   # Conv2D then ReLU activation\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "   # add another Conv2D layer\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "   # add another Conv2D layer\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "\n",
        "   return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "M4rjSNjE4L9i"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2OYaRXbZ5wWW"
      },
      "outputs": [],
      "source": [
        " # inputs\n",
        "import tensorflow.keras.layers as layers\n",
        " \n",
        "inputs = layers.Input(shape=(256,256,1))\n",
        "\n",
        "# encoder: contracting path - downsample\n",
        "# 1 - downsample\n",
        "f1, p1 = downsample_block(inputs, 64)\n",
        "# 2 - downsample\n",
        "f2, p2 = downsample_block(p1, 128)\n",
        "# 3 - downsample\n",
        "f3, p3 = downsample_block(p2, 256)\n",
        "# 4 - downsample\n",
        "f4, p4 = downsample_block(p3, 512)\n",
        "\n",
        "# 5 - bottleneck\n",
        "bottleneck = double_conv_block(p4, 1024)\n",
        "\n",
        "# decoder: expanding path - upsample\n",
        "# 6 - upsample\n",
        "u6 = upsample_block(bottleneck, f4, 512)\n",
        "# 7 - upsample\n",
        "u7 = upsample_block(u6, f3, 256)\n",
        "# 8 - upsample\n",
        "u8 = upsample_block(u7, f2, 128)\n",
        "# 9 - upsample\n",
        "u9 = upsample_block(u8, f1, 64)\n",
        "\n",
        "# outputs\n",
        "outputs = layers.Conv2D(num_classes, 1, padding=\"same\", activation = \"softmax\")(u9)\n",
        "\n",
        "# unet model with Keras Functional API\n",
        "unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RJeesHOhHqCL",
        "outputId": "8bc792e4-ce47-466f-8001-6ec7a689e9a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"U-Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 256, 256, 64  640         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['conv2d[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 256, 256, 64  36928       ['conv2d_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 256, 256, 64  36928       ['conv2d_2[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['conv2d_3[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 128, 128, 64  0           ['max_pooling2d[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 128, 128, 12  73856       ['dropout[0][0]']                \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_4[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_5[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_6[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 64, 64, 128)  0           ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 64, 64, 256)  295168      ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 64, 64, 256)  590080      ['conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['conv2d_11[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 32, 32, 256)  0           ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 32, 32, 512)  1180160     ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0          ['conv2d_15[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 16, 16, 512)  0           ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 16, 16, 1024  4719616     ['dropout_3[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 16, 16, 1024  9438208     ['conv2d_16[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 16, 16, 1024  9438208     ['conv2d_17[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 16, 16, 1024  9438208     ['conv2d_18[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 32, 32, 512)  4719104    ['conv2d_19[0][0]']              \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 32, 32, 1024  0           ['conv2d_transpose[0][0]',       \n",
            "                                )                                 'conv2d_15[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 32, 32, 1024  0           ['concatenate[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 32, 32, 512)  4719104     ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_20[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_23[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 256)  1179904    ['conv2d_24[0][0]']              \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 64, 64, 512)  0           ['conv2d_transpose_1[0][0]',     \n",
            "                                                                  'conv2d_11[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 64, 64, 512)  0           ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 64, 64, 256)  1179904     ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_27[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_28[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 12  295040     ['conv2d_29[0][0]']              \n",
            " spose)                         8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 128, 128, 25  0           ['conv2d_transpose_2[0][0]',     \n",
            "                                6)                                'conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 128, 128, 25  0           ['concatenate_2[0][0]']          \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 128, 128, 12  295040      ['dropout_6[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_30[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_31[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_32[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_33[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 64  73792      ['conv2d_34[0][0]']              \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 256, 256, 12  0           ['conv2d_transpose_3[0][0]',     \n",
            "                                8)                                'conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 256, 256, 12  0           ['concatenate_3[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 256, 256, 64  73792       ['dropout_7[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_35[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_36[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_37[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_38[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 256, 256, 4)  260         ['conv2d_39[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 69,060,804\n",
            "Trainable params: 69,060,804\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "unet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fME0ebJ72YaT"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "\n",
        "# x = unet_model.outputs\n",
        "\n",
        "# # Compile the model\n",
        "# unet_model = keras.Model(inputs, x)\n",
        "unet_model.compile(optimizer='ADAM', loss=tf.losses.CategoricalCrossentropy(), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Yf2v-J7p2Yc6",
        "outputId": "d93b8f0b-5383-4732-b594-a08a1de0f65a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17, 256, 256, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "image_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KRpK9z2UFmjc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "S1zutHpFYuTh"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(image_data, one_hot_labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "livp2L57b2FC",
        "outputId": "b6a976cf-4787-412d-b519-408b1e9ac5ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 256, 256, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "train_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IyK3g-33Cn5f",
        "outputId": "90939b43-119e-4577-e457-71dc572be381"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 256, 256, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "H9-wCkBOvLst",
        "outputId": "3661874d-6701-4162-d384-99a1bc4d3dba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 256, 256, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "test_labels.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KzpiviOJFo8g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "oPuMkIdKCnCa",
        "outputId": "c9e7b733-b413-4ae0-90dd-bd05f9d151ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 256, 256, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "test_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "n6METtkbZ90l",
        "outputId": "d765344a-4c28-49bc-9b74-5c22254e3e16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "13/13 [==============================] - 270s 18s/step - loss: 218.6926 - accuracy: 0.4297 - val_loss: 7.7663 - val_accuracy: 0.2627\n",
            "Epoch 2/5\n",
            "13/13 [==============================] - 239s 19s/step - loss: 4.7213 - accuracy: 0.5242 - val_loss: 2.3999 - val_accuracy: 0.4725\n",
            "Epoch 3/5\n",
            "13/13 [==============================] - 235s 18s/step - loss: 3.2132 - accuracy: 0.5195 - val_loss: 1.1879 - val_accuracy: 0.5566\n",
            "Epoch 4/5\n",
            "13/13 [==============================] - 235s 18s/step - loss: 1.3702 - accuracy: 0.4873 - val_loss: 1.1631 - val_accuracy: 0.5660\n",
            "Epoch 5/5\n",
            "13/13 [==============================] - 230s 18s/step - loss: 1.3734 - accuracy: 0.5635 - val_loss: 1.1911 - val_accuracy: 0.5839\n"
          ]
        }
      ],
      "source": [
        "history = unet_model.fit(datagen.flow(train_images, train_labels, batch_size=1), epochs=5, validation_data=(test_images, test_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = unet_model.fit(datagen.flow(train_images, train_labels, batch_size=1), epochs=5, validation_data=(test_images, test_labels))\n"
      ],
      "metadata": {
        "id": "3t3tih4dL6d1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "fmcRU32GDNeU"
      },
      "outputs": [],
      "source": [
        "unet_model.save('unet_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unet_model.h5"
      ],
      "metadata": {
        "id": "xQm1TqydH2qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = unet_model.fit(datagen.flow(train_images, train_labels, batch_size=1), epochs=5, validation_data=(test_images, test_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "20dBUv18NQk5",
        "outputId": "4907ba95-597b-46b8-bf33-d834bfbda272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "13/13 [==============================] - 235s 18s/step - loss: 1.8524 - accuracy: 0.5364 - val_loss: 1.1859 - val_accuracy: 0.4555\n",
            "Epoch 2/5\n",
            "13/13 [==============================] - 232s 18s/step - loss: 1.2279 - accuracy: 0.5755 - val_loss: 1.1411 - val_accuracy: 0.5876\n",
            "Epoch 3/5\n",
            "13/13 [==============================] - 231s 18s/step - loss: 1.0746 - accuracy: 0.5931 - val_loss: 1.0030 - val_accuracy: 0.5947\n",
            "Epoch 4/5\n",
            "10/13 [======================>.......] - ETA: 48s - loss: 0.9864 - accuracy: 0.5966 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unet_model.save('unet_modeltrial2.h5')"
      ],
      "metadata": {
        "id": "qzYaY4T0NUej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "GtfOB0FdIblz",
        "outputId": "afb36ec3-c2a9-4ec9-bdb0-425c0b2a839e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-c3758168d0ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
          ]
        }
      ],
      "source": [
        "print(predictions.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_ZgmI7CKDPj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZbySH7zKDia"
      },
      "outputs": [],
      "source": [
        "unet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcwUgCEHIcn1"
      },
      "outputs": [],
      "source": [
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVr47jj7I66h"
      },
      "outputs": [],
      "source": [
        "print(np.argmax(predictions[0], axis=-3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "I-PlpVH5COj-",
        "outputId": "90bb8f10-945c-47c8-e41b-84bb2f14d712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n"
          ]
        }
      ],
      "source": [
        "import cv2 # Load the test image in color format\n",
        "test_image = cv2.imread('test_image.jpg')\n",
        "\n",
        "# Resize the test image to the desired size\n",
        "test_image = cv2.resize(test_image, (256, 256))\n",
        "\n",
        "# Convert the test image to grayscale\n",
        "gray_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Preprocess the test image\n",
        "gray_image = gray_image.astype('float32') / 255.0\n",
        "\n",
        "# Reshape the grayscale image to match the model input shape\n",
        "gray_image = gray_image.reshape((1, 256, 256, 1))\n",
        "\n",
        "# Make predictions on the test image\n",
        "predictions = unet_model.predict(gray_image)\n",
        "\n",
        "# Get the predicted class labels for the test image\n",
        "#predicted_labels = np.eye()[np.argmax(predictions[0], axis=-1)]\n",
        "\n",
        "predicted_labels= np.argmax(np.max(predictions[0], axis=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4Kh2tnF7CjAL",
        "outputId": "0d41e6ae-3fd0-4937-a553-1b3c7074f04e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[0.26578394 0.24468973 0.23318116 0.25634518]\n",
            "   [0.26706606 0.24493198 0.23169404 0.256308  ]\n",
            "   [0.26659793 0.24462302 0.23262827 0.25615072]\n",
            "   ...\n",
            "   [0.2676026  0.244005   0.23271525 0.25567716]\n",
            "   [0.26712006 0.24412797 0.23248774 0.25626418]\n",
            "   [0.2652217  0.24460799 0.23254867 0.25762162]]\n",
            "\n",
            "  [[0.26656577 0.24548213 0.23134154 0.2566106 ]\n",
            "   [0.26826307 0.24607593 0.22920191 0.25645906]\n",
            "   [0.26877448 0.24599934 0.22960284 0.25562337]\n",
            "   ...\n",
            "   [0.27072453 0.24559452 0.22896327 0.25471768]\n",
            "   [0.26965466 0.24479175 0.23033378 0.2552199 ]\n",
            "   [0.26702413 0.24435902 0.2318363  0.25678053]]\n",
            "\n",
            "  [[0.26719156 0.24532616 0.23117422 0.2563081 ]\n",
            "   [0.27080923 0.24592125 0.22775082 0.2555186 ]\n",
            "   [0.27054456 0.24692887 0.22573291 0.2567936 ]\n",
            "   ...\n",
            "   [0.2741673  0.24736181 0.22525303 0.25321785]\n",
            "   [0.2733031  0.24656615 0.2263647  0.25376615]\n",
            "   [0.2687761  0.24549386 0.22891593 0.25681418]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.2663009  0.24586403 0.2307432  0.25709182]\n",
            "   [0.26812008 0.24682297 0.22802535 0.25703162]\n",
            "   [0.26892373 0.24630323 0.22780283 0.2569703 ]\n",
            "   ...\n",
            "   [0.26879612 0.24603643 0.22867814 0.25648937]\n",
            "   [0.26803356 0.24596728 0.22925618 0.2567431 ]\n",
            "   [0.2664621  0.2452108  0.23023917 0.25808796]]\n",
            "\n",
            "  [[0.2664589  0.24574538 0.23108321 0.25671247]\n",
            "   [0.26824352 0.24673691 0.22835529 0.2566642 ]\n",
            "   [0.26880234 0.24636844 0.227852   0.25697717]\n",
            "   ...\n",
            "   [0.2682735  0.24636365 0.22810829 0.25725463]\n",
            "   [0.268237   0.24616736 0.22849028 0.25710526]\n",
            "   [0.26649415 0.24550231 0.22938178 0.25862163]]\n",
            "\n",
            "  [[0.26577237 0.24572314 0.23153552 0.256969  ]\n",
            "   [0.2669223  0.24581411 0.22960293 0.25766066]\n",
            "   [0.26724142 0.24586475 0.22951847 0.25737545]\n",
            "   ...\n",
            "   [0.26730776 0.24582224 0.22946434 0.25740573]\n",
            "   [0.2666137  0.24586587 0.22960891 0.2579114 ]\n",
            "   [0.26585594 0.245629   0.22992277 0.25859243]]]]\n"
          ]
        }
      ],
      "source": [
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.argmax(np.max(predictions[0], axis=2)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kACpVsdWJC0G",
        "outputId": "dd6f5b63-b021-46a2-c50a-9f9ebbbe45cb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0o497LE3My8J"
      },
      "outputs": [],
      "source": [
        "for i in range(0,255):\n",
        "    for j in range (0,255):\n",
        "        print(np.argmax(predictions[0,i,j]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YlLO7hGiNnay",
        "outputId": "7fec4c7b-7fe2-4b9e-a1d5-33a7637fd67b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[    0 65025]]\n"
          ]
        }
      ],
      "source": [
        "temp=[]\n",
        "for i in range(0,255):\n",
        "    for j in range (0,255):\n",
        "        temp.append(np.argmax(predictions[0,i,j]))\n",
        "temp=np.array(temp)\n",
        "unique, counts = np.unique(temp, return_counts=True)\n",
        "print(np.asarray((unique, counts)).T)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(counts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9yoNFeHbMOi2",
        "outputId": "5b431af9-a68e-473c-d803-e2a12c43a5df"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qnn69g48M2Kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aTWZJiY1M2W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AFn2v5FvM2a7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################################################################################################"
      ],
      "metadata": {
        "id": "eNx4cGBDM2eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CXLH5W8Qwbu"
      },
      "outputs": [],
      "source": [
        "# Assuming you have `predicted_labels` as an array of shape (1, 256, 256, 4) containing the predicted labels\n",
        "num_classes = 4\n",
        "\n",
        "# Create an empty array to store the one-hot encoded labels\n",
        "predicted_one_hot_labels = np.zeros((1, 256, 256, num_classes))\n",
        "\n",
        "# Iterate over the predicted label images\n",
        "for i in range(predicted_labels.shape[0]):\n",
        "    # One-hot encode the predicted labels\n",
        "    for j in range(num_classes):\n",
        "        predicted_one_hot_labels[i,:,:,j] = (predicted_labels[:,:,:] == j)\n",
        "\n",
        "# Get the index of the class with the highest probability\n",
        "predicted_label_index = np.argmax(predicted_one_hot_labels, axis=-1)\n",
        "\n",
        "# Get the name of the class\n",
        "class_names = ['Background','panel','panelWfrost','Thicksnow']\n",
        "\n",
        "# Display the one-hot encoded image\n",
        "img = predicted_label_index[0]\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "# Count the number of pixels in each class\n",
        "class_counts = []\n",
        "for i in range(num_classes):\n",
        "    class_mask = np.where(predicted_label_index[0] == i, 1, 0)\n",
        "    class_counts.append(np.sum(class_mask))\n",
        "\n",
        "# Display the class counts\n",
        "for i in range(num_classes):\n",
        "    print(f\"Number of pixels in class '{class_names[i]}': {class_counts[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5-Zae6XO1dg"
      },
      "outputs": [],
      "source": [
        "predicted_one_hot_labels = np.zeros((1, 256, 256, num_classes))\n",
        "# One-hot encode the predicted labels\n",
        "for j in range(num_classes):\n",
        "    predicted_one_hot_labels[:,:,j] = (predicted_labels == j)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aeJPbA5CO0j"
      },
      "outputs": [],
      "source": [
        "# Assuming you have `predicted_labels` as an array of shape (1, 256, 256, 4) containing the predicted labels\n",
        "num_classes = 4\n",
        "\n",
        "# Create an empty array to store the one-hot encoded labels\n",
        "predicted_one_hot_labels = np.zeros((1, 256, 256, num_classes))\n",
        "\n",
        "# Iterate over the predicted label images\n",
        "for i in range(predicted_labels.shape[0]):\n",
        "    # One-hot encode the predicted labels\n",
        "    for j in range(num_classes):\n",
        "        predicted_one_hot_labels[i,:,:,j] = (predicted_labels[:,:,:] == j)\n",
        "\n",
        "# Get the index of the class with the highest probability\n",
        "predicted_label_index = np.argmax(predicted_one_hot_labels, axis=-1)\n",
        "\n",
        "# Get the name of the class\n",
        "class_names = ['Background','panel','panelWfrost','Thicksnow']\n",
        "\n",
        "# Display the one-hot encoded image\n",
        "img = predicted_label_index[0]\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "# Count the number of pixels in each class\n",
        "class_counts = []\n",
        "for i in range(num_classes):\n",
        "    class_mask = np.where(predicted_label_index[0] == i, 1, 0)\n",
        "    class_counts.append(np.sum(class_mask))\n",
        "\n",
        "# Display the class counts\n",
        "for i in range(num_classes):\n",
        "    print(f\"Number of pixels in class '{class_names[i]}': {class_counts[i]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puvtMQR6CO6m"
      },
      "outputs": [],
      "source": [
        "print(predicted_one_hot_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-PPKs5-CPD1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzInzd-HCPHV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGdSM59lg5u2"
      },
      "outputs": [],
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "\n",
        "# Define the color coding for each class\n",
        "class_colors = [(0, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
        "\n",
        "# Load the test image and ground truth mask in color format\n",
        "test_image = cv2.imread('test_image.jpg')\n",
        "ground_truth_mask = cv2.imread('ground_truth_mask.png')\n",
        "\n",
        "# Resize the test image and ground truth mask to the desired size\n",
        "test_image = cv2.resize(test_image, (256, 256))\n",
        "ground_truth_mask = cv2.resize(ground_truth_mask, (256, 256))\n",
        "\n",
        "# Convert the test image and ground truth mask to grayscale\n",
        "gray_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
        "gray_ground_truth_mask = cv2.cvtColor(ground_truth_mask, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Preprocess the test image\n",
        "gray_image = gray_image.astype('float32') / 255.0\n",
        "\n",
        "# Reshape the grayscale image to match the model input shape\n",
        "gray_image = gray_image.reshape((1, 256, 256, 1))\n",
        "\n",
        "# Make predictions on the test image\n",
        "predictions = unet_model.predict(gray_image)\n",
        "\n",
        "# Get the predicted class labels for the test image\n",
        "predicted_labels = np.argmax(predictions[0], axis=-1)\n",
        "\n",
        "# Apply color coding to the predicted image and the ground truth image\n",
        "predicted_mask = np.zeros_like(test_image)\n",
        "ground_truth_colored = np.zeros_like(ground_truth_mask)\n",
        "for i, color in enumerate(class_colors):\n",
        "    predicted_mask[predicted_labels == i] = color\n",
        "    ground_truth_colored[gray_ground_truth_mask == i * 255] = color\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Display the predicted image and the ground truth image\n",
        "cv2_imshow( predicted_mask)\n",
        "cv2_imshow( ground_truth_colored)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvtVUpGSglZe"
      },
      "outputs": [],
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "\n",
        "# Define the color coding for each class\n",
        "class_colors = [(0, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
        "\n",
        "# Load the test image and ground truth mask in color format\n",
        "test_image = cv2.imread('test_image.jpg')\n",
        "ground_truth_mask = cv2.imread('ground_truth_mask.png')\n",
        "\n",
        "# Convert the test image and ground truth mask to grayscale\n",
        "gray_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
        "gray_ground_truth_mask = cv2.cvtColor(ground_truth_mask, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Resize the test image to 256x256\n",
        "gray_image = cv2.resize(gray_image, (256, 256), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "# Preprocess the test image\n",
        "gray_image = gray_image.astype('float32') / 255.0\n",
        "\n",
        "# Reshape the grayscale image to match the model input shape\n",
        "gray_image = gray_image.reshape((1, 256, 256, 1))\n",
        "\n",
        "# Make predictions on the test image\n",
        "predictions = unet_model.predict(gray_image)\n",
        "\n",
        "# Get the predicted class labels for the test image\n",
        "predicted_labels = np.argmax(predictions[0], axis=-1)\n",
        "\n",
        "# Apply color coding to the predicted image and the ground truth image\n",
        "predicted_mask = np.zeros_like(test_image)\n",
        "ground_truth_colored = np.zeros_like(ground_truth_mask)\n",
        "for i, color in enumerate(class_colors):\n",
        "    predicted_mask[predicted_labels == i] = color\n",
        "    ground_truth_colored[gray_ground_truth_mask == i * 255] = color\n",
        "\n",
        "# Display the predicted image and the ground truth image\n",
        "cv2.imshow('Predicted Mask', predicted_mask)\n",
        "cv2.imshow('Ground Truth Mask', ground_truth_colored)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZNdBGO0fzSx"
      },
      "outputs": [],
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "\n",
        "# Define the color coding for each class\n",
        "class_colors = [(0, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
        "\n",
        "# Load the test image and ground truth mask in color format\n",
        "test_image = cv2.imread('test_image.jpg')\n",
        "ground_truth_mask = cv2.imread('ground_truth_mask.png')\n",
        "\n",
        "# Convert the test image and ground truth mask to grayscale\n",
        "gray_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
        "gray_ground_truth_mask = cv2.cvtColor(ground_truth_mask, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Preprocess the test image\n",
        "gray_image = cv2.resize(gray_image, (256, 256))\n",
        "gray_image = gray_image.astype('float32') / 255.0\n",
        "\n",
        "# Reshape the grayscale image to match the model input shape\n",
        "gray_image = gray_image.reshape((1, 256, 256, 1))\n",
        "\n",
        "# Make predictions on the test image\n",
        "predictions = unet_model.predict(gray_image)\n",
        "\n",
        "# Get the predicted class labels for the test image\n",
        "predicted_labels = np.argmax(predictions[0], axis=-1)\n",
        "\n",
        "# Apply color coding to the predicted image and the ground truth image\n",
        "predicted_mask = np.zeros_like(test_image)\n",
        "ground_truth_colored = np.zeros_like(ground_truth_mask)\n",
        "for i, color in enumerate(class_colors):\n",
        "    predicted_mask[predicted_labels == i] = color\n",
        "    ground_truth_colored[gray_ground_truth_mask == i * 255] = color\n",
        "\n",
        "# Display the predicted image and the ground truth image\n",
        "cv2.imshow('Predicted Mask', predicted_mask)\n",
        "cv2.imshow('Ground Truth Mask)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGt_BOIjfznU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xk6Ieg_dmcb"
      },
      "outputs": [],
      "source": [
        "import cv2 \n",
        "# Load the test image in color format\n",
        "test_image = cv2.imread('test_image.jpg')\n",
        "\n",
        "# Convert the test image to grayscale\n",
        "gray_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Preprocess the test image\n",
        "gray_image = cv2.resize(gray_image, (256, 256))\n",
        "gray_image = gray_image.astype('float32') / 255.0\n",
        "\n",
        "# Reshape the grayscale image to match the model input shape\n",
        "gray_image = gray_image.reshape((1, 256, 256, 1))\n",
        "\n",
        "# Make predictions on the test image\n",
        "predictions = unet_model.predict(gray_image)\n",
        "\n",
        "# Get the predicted class labels for the test image\n",
        "predicted_labels = np.argmax(predictions[0], axis=-1)\n",
        "\n",
        "# Calculate the pixel counts for each class in the predicted labels\n",
        "class_counts = []\n",
        "for i in range(num_classes):\n",
        "    class_mask = np.where(predicted_labels == i, 1, 0)\n",
        "    class_counts.append(np.sum(class_mask))\n",
        "    \n",
        "# Print the pixel counts for each class\n",
        "print('Pixel counts for each class:', class_counts)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVDwBQJW_RaK"
      },
      "outputs": [],
      "source": [
        "print(class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJ6SyTVbdnQs"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the test image in color format\n",
        "test_image = cv2.imread('test_image.jpg')\n",
        "\n",
        "# Convert the test image to grayscale\n",
        "gray_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Preprocess the test image\n",
        "gray_image = cv2.resize(gray_image, (256, 256))\n",
        "gray_image = gray_image.astype('float32') / 255.0\n",
        "\n",
        "# Reshape the grayscale image to match the model input shape\n",
        "gray_image = gray_image.reshape((1, 256, 256, 1))\n",
        "\n",
        "# Make predictions on the test image\n",
        "predictions = unet_model.predict(gray_image)\n",
        "\n",
        "# Get the predicted class labels for the test image\n",
        "predicted_labels = np.argmax(predictions[0], axis=-1)\n",
        "\n",
        "# Plot the test image and predicted segmentation mask\n",
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n",
        "ax1.imshow(test_image)\n",
        "ax1.set_title('Test Image')\n",
        "ax2.imshow(predicted_labels, cmap='gray')\n",
        "ax2.set_title('Segmentation Mask')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PGJhimxYZDA"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1OxxjGAlLDM6WmXB2VgHi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}