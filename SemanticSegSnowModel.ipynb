{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NouranShaaban/workshop_geopython2019/blob/master/SemanticSegSnowModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-m9Jl447zhDy"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjxQkPu217nV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "import glob\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow.keras.layers as layers\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNqsLyCc17qA"
      },
      "outputs": [],
      "source": [
        "# Set the directory where the images are stored\n",
        "image_dir = '/content/drive/MyDrive/DATASET/newlabels_train/JPEGImages'\n",
        "\n",
        "# Create an empty list to store the image data\n",
        "image_data = []\n",
        "\n",
        "# Use glob to get a list of all the image filenames\n",
        "filenames = glob.glob(image_dir + '/*.jpg')\n",
        "\n",
        "# Loop through the filenames and load the images\n",
        "for filename in filenames:\n",
        "    # Load the image and convert it to grayscale\n",
        "    image = Image.open(filename).convert('L')\n",
        "  \n",
        "    # Resize the image to a consistent size\n",
        "    image = image.resize((256, 256))\n",
        "    # Convert the image to a numpy array\n",
        "    image_array = np.array(image)\n",
        "    \n",
        "    # Append the image array to the list\n",
        "    image_data.append(image_array)\n",
        "\n",
        "# Convert the list of image arrays to a NumPy array\n",
        "image_data = np.array(image_data)\n",
        "\n",
        "# Save the image data to a file\n",
        "np.save('image_data.npy', image_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lc3OdKlt17si"
      },
      "outputs": [],
      "source": [
        "image_data = image_data.reshape((-1,256,256,1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_89rfZw017vF"
      },
      "outputs": [],
      "source": [
        "# Set the directory where the images are stored\n",
        "label_dir = '/content/drive/MyDrive/DATASET/newlabels_train/SegmentationClassPNG'\n",
        "\n",
        "# Create an empty list to store the image data\n",
        "label_data = []\n",
        "# Number of classes\n",
        "num_classes = 4\n",
        "\n",
        "# Use glob to get a list of all the image filenames\n",
        "filenames = glob.glob(label_dir + '/*.png')\n",
        "\n",
        "# Loop through the filenames and load the images\n",
        "for filename in filenames:\n",
        "    # Load the image and convert it to grayscale\n",
        "    label = Image.open(filename)#.convert('L')\n",
        "    \n",
        "    # Resize the image to a consistent size\n",
        "    label = label.resize((256, 256))\n",
        "    # Convert the image to a numpy array\n",
        "    label_array = np.array(label)\n",
        " \n",
        "    \n",
        "    # Append the image array to the list\n",
        "    label_data.append(label_array)\n",
        "\n",
        "label_data = np.array(label_data)\n",
        "\n",
        "# Save the image data to a file\n",
        "np.save('label_data.npy', label_data)\n",
        "\n",
        "##########################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBe4QTw517xR"
      },
      "outputs": [],
      "source": [
        "label_data.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kF1d0Ty417z7"
      },
      "outputs": [],
      "source": [
        "\n",
        "one_hot_labels = np.zeros((len(label_data), 256, 256, num_classes))\n",
        "\n",
        "# Iterate over the label images\n",
        "for i, label_image in enumerate(label_data):\n",
        "    # one-hot encode the labels\n",
        "    one_hot_labels[i] = np.eye(num_classes)[label_image]\n",
        "\n",
        "    class_names = ['Background','panel','panelWfrost','Thicknow']\n",
        "\n",
        "# Get the index of the class with the highest probability\n",
        "label_index = np.argmax(one_hot_labels, axis=-1)\n",
        "\n",
        "# Get the name of the class\n",
        "label_index = label_index.astype(int)\n",
        "class_name = np.vectorize(lambda x: class_names[x])(label_index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Gre9jE5172Z"
      },
      "outputs": [],
      "source": [
        "one_hot_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gwBvqRm1741"
      },
      "outputs": [],
      "source": [
        "one_hot_labels[0,:,:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV9GPeS-177Q"
      },
      "outputs": [],
      "source": [
        "# Load the image data\n",
        "label_data = np.load('label_data.npy')\n",
        "\n",
        "# Number of classes\n",
        "num_classes = 4\n",
        "\n",
        "# Create an empty array to store the one-hot encoded labels\n",
        "one_hot_labels = np.zeros((len(label_data), 256, 256, num_classes))\n",
        "\n",
        "# Iterate over the label images\n",
        "for i, label_image in enumerate(label_data):\n",
        "    # One-hot encode the labels\n",
        "    for j in range(num_classes):\n",
        "        one_hot_labels[i,:,:,j] = (label_image == j)\n",
        "\n",
        "# Get the index of the class with the highest probability\n",
        "label_index = np.argmax(one_hot_labels, axis=-1)\n",
        "\n",
        "# Get the name of the class\n",
        "class_names = ['Background','panel','panelWfrost','Thicksnow']\n",
        "\n",
        "# display the one-hot encoded image\n",
        "img = label_index[1]\n",
        "plt.imshow(img)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncmCTCos179w"
      },
      "outputs": [],
      "source": [
        "class_3 = np.where(label_index[93] == 0, 1,0)\n",
        "class_3 = class_3.reshape((256,256))\n",
        "plt.imshow(class_3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTux8cGt18AW"
      },
      "outputs": [],
      "source": [
        "class_counts = []\n",
        "for i in range(num_classes):\n",
        "    class_mask = np.where(label_index[93] == i, 1, 0)\n",
        "    class_counts.append(np.sum(class_mask))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aDZgKoS18DB"
      },
      "outputs": [],
      "source": [
        "print(class_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9i3IAF7Y2YSA"
      },
      "outputs": [],
      "source": [
        "def upsample_block(x, conv_features, n_filters):\n",
        "   # upsample\n",
        "   x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
        "   # concatenate\n",
        "   x = layers.concatenate([x, conv_features])\n",
        "   # dropout\n",
        "   x = layers.Dropout(0.3)(x)\n",
        "   # Conv2D twice with ReLU activation\n",
        "   x = double_conv_block(x, n_filters)\n",
        "   # add another Conv2D layer\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "\n",
        "   return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVMQYuy72YU2"
      },
      "outputs": [],
      "source": [
        "def downsample_block(x, n_filters):\n",
        "   f = double_conv_block(x, n_filters)\n",
        "   p = layers.MaxPool2D(2)(f)\n",
        "   p = layers.Dropout(0.3)(p)\n",
        "\n",
        "   return f, p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icMPQTy82YXs"
      },
      "outputs": [],
      "source": [
        "def double_conv_block(x, n_filters):\n",
        "   # Conv2D then ReLU activation\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "   # Conv2D then ReLU activation\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "   # add another Conv2D layer\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "   # add another Conv2D layer\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "\n",
        "   return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4rjSNjE4L9i"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OYaRXbZ5wWW"
      },
      "outputs": [],
      "source": [
        " # inputs\n",
        "import tensorflow.keras.layers as layers\n",
        " \n",
        "inputs = layers.Input(shape=(256,256,1))\n",
        "\n",
        "# encoder: contracting path - downsample\n",
        "# 1 - downsample\n",
        "f1, p1 = downsample_block(inputs, 64)\n",
        "# 2 - downsample\n",
        "f2, p2 = downsample_block(p1, 128)\n",
        "# 3 - downsample\n",
        "f3, p3 = downsample_block(p2, 256)\n",
        "# 4 - downsample\n",
        "f4, p4 = downsample_block(p3, 512)\n",
        "\n",
        "# 5 - bottleneck\n",
        "bottleneck = double_conv_block(p4, 1024)\n",
        "\n",
        "# decoder: expanding path - upsample\n",
        "# 6 - upsample\n",
        "u6 = upsample_block(bottleneck, f4, 512)\n",
        "# 7 - upsample\n",
        "u7 = upsample_block(u6, f3, 256)\n",
        "# 8 - upsample\n",
        "u8 = upsample_block(u7, f2, 128)\n",
        "# 9 - upsample\n",
        "u9 = upsample_block(u8, f1, 64)\n",
        "\n",
        "# outputs\n",
        "outputs = layers.Conv2D(4, 1, padding=\"same\", activation = \"softmax\")(u9)\n",
        "\n",
        "# unet model with Keras Functional API\n",
        "unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJeesHOhHqCL"
      },
      "outputs": [],
      "source": [
        "unet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fME0ebJ72YaT"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "\n",
        "x = unet_model.outputs\n",
        "\n",
        "# Compile the model\n",
        "unet_model = keras.Model(inputs, x)\n",
        "unet_model.compile(optimizer='adam', loss=tf.losses.CategoricalCrossentropy(), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yf2v-J7p2Yc6"
      },
      "outputs": [],
      "source": [
        "image_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1zutHpFYuTh"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(image_data, one_hot_labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "livp2L57b2FC"
      },
      "outputs": [],
      "source": [
        "train_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyK3g-33Cn5f"
      },
      "outputs": [],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9-wCkBOvLst"
      },
      "outputs": [],
      "source": [
        "test_labels.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPuMkIdKCnCa"
      },
      "outputs": [],
      "source": [
        "test_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/DATASET/newlabels_train/unet_model (1).h5')"
      ],
      "metadata": {
        "id": "THwJfKYWbE61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6METtkbZ90l"
      },
      "outputs": [],
      "source": [
        "history = unet_model.fit(datagen.flow(train_images, train_labels, batch_size=10), epochs=30, validation_data=(test_images, test_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = unet_model.fit(datagen.flow(train_images, train_labels, batch_size=10), epochs=5, validation_data=(test_images, test_labels))\n"
      ],
      "metadata": {
        "id": "U2qvN9mUm-HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmcRU32GDNeU"
      },
      "outputs": [],
      "source": [
        "unet_model.save('unet_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5EyQHKnUy9w"
      },
      "outputs": [],
      "source": [
        "import cv2 # Load the test image in color format\n",
        "test_image = cv2.imread('test_image.jpg')\n",
        "\n",
        "# Resize the test image to the desired size\n",
        "test_image = cv2.resize(test_image, (256, 256))\n",
        "\n",
        "# Convert the test image to grayscale\n",
        "gray_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Preprocess the test image\n",
        "gray_image = gray_image.astype('float32') / 255.0\n",
        "\n",
        "# Reshape the grayscale image to match the model input shape\n",
        "gray_image = gray_image.reshape((1, 256, 256, 1))\n",
        "\n",
        "# Make predictions on the test image\n",
        "predictions = unet_model.predict(gray_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4x-LGgB7UzB7"
      },
      "outputs": [],
      "source": [
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9E1mK1KUzEv"
      },
      "outputs": [],
      "source": [
        "temp=[]\n",
        "for i in range(0,255):\n",
        "    for j in range (0,255):\n",
        "        temp.append(np.argmax(predictions[0,i,j]))\n",
        "temp=np.array(temp)\n",
        "unique, counts = np.unique(temp, return_counts=True)\n",
        "print(np.asarray((unique, counts)).T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWaiyR7aUzHn"
      },
      "outputs": [],
      "source": [
        "print(counts[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_orXAI6UzK1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPLboax3UzNl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1dLd1TR0j-Key4KGezWQbC5-yFglwu7Iw",
      "authorship_tag": "ABX9TyOBlRVZ2aCdvq/3RmzGiUvJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}